{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_ngrok import run_with_ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import flask\n",
    "app = flask.Flask(__name__)\n",
    "\n",
    "run_with_ngrok(app)\n",
    "from flask import Flask, render_template, request\n",
    "\n",
    "#load model preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.models\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer for preprocessing\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "# Load pre-trained model into memory\n",
    "json_file = open('model.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepData(text):\n",
    "    # Convert to array\n",
    "    textDataArray = [text]\n",
    "    \n",
    "    # Convert into list with word ids\n",
    "    Features = tokenizer.texts_to_sequences(textDataArray)\n",
    "    Features = pad_sequences(Features, 20, padding='post')\n",
    "    \n",
    "    return Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(optimizer=\"Adam\",loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-384904600fda>:3: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  out = np.asscalar(loaded_model.predict(textTokenizedTest))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.022943735122680664"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textDataTest = 'Hey! How was dinner last night?'\n",
    "textTokenizedTest = prepData(textDataTest)\n",
    "out = np.asscalar(loaded_model.predict(textTokenizedTest))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-93d70c5ab13b>:3: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  out = np.asscalar(loaded_model.predict(textTokenizedTest))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9085490703582764"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textDataTest = 'Your account has been hacked. Please call 1-800-0000 to speak with a representative'\n",
    "textTokenizedTest = prepData(textDataTest)\n",
    "out = np.asscalar(loaded_model.predict(textTokenizedTest))\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See above. The first message had a 2% probability being spam and the second had a 91% chance. \n",
    "Our pre-trained model is working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a predict function as an endpoint \n",
    "\n",
    "@app.route('/', methods=['GET','POST'])\n",
    "def predict():\n",
    "    \n",
    "    #whenever the predict method is called, we're going\n",
    "    #to input the user entered text into the model\n",
    "    #and return a prediction\n",
    "    \n",
    "    if request.method=='POST':\n",
    "        \n",
    "        #Note: for local run, we print information to debug and understand how app is working\n",
    "        \n",
    "        textData = request.form.get('text_entered')\n",
    "        print(textData)\n",
    "\n",
    "        Features = prepData(textData)\n",
    "        print(Features)\n",
    "        \n",
    "        prediction = int((np.asscalar(loaded_model.predict(Features)))*100)\n",
    "        print(prediction)\n",
    "        \n",
    "        #return prediction in new page\n",
    "        return render_template('prediction.html', prediction=prediction)\n",
    "    \n",
    "    else:\n",
    "        return render_template(\"search_page.html\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The block below may return error message \"UnsupportedOperation: not writable\". Follow instructions below to correct error if encountered.\n",
    "\n",
    "Option 1 is to edit the echo and secho functions:\n",
    "\n",
    "(1) find conda environment location in C:\\Users\\[user]\\.conda\\environments.txt (it is in file)\n",
    "\n",
    "(2) go to this location on your computer\n",
    "\n",
    "(3) go to anaconda3/site-packages/click folder on your computer\n",
    "\n",
    "(4) open utils.py in this folder\n",
    "\n",
    "(5) find “def echo” and change parameter “file=None” to “file=sys.stdout”\n",
    "\n",
    "(6) open termui.py in this folder\n",
    "\n",
    "(7) find “def secho” and change parameter “file=None” to “file=sys.stdout”\n",
    "\n",
    "\n",
    "Option 2 is to refer to an older version of flask:\n",
    "\n",
    "(1) open anaconda prompt\n",
    "\n",
    "(2) “pip uninstall flask”\n",
    "\n",
    "(3) “pip install flask=0.12.2”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [16/Nov/2021 19:40:41] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #decide what port to run the app in\n",
    "    port = int(os.environ.get('PORT', 5000))\n",
    "       \n",
    "    #run the app locally on the given port\n",
    "    app.run(host='localhost', port=port) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
